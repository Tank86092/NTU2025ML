{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tank86092/2025ML/blob/main/2025ML_HW1_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **2025 ML FALL HW1: PM2.5 Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: MLTAs\n",
        "\n",
        "Methods:\n",
        "* Training with all data\n",
        "* Optimizer: RMSProp (default)\n",
        "* TODOs:\n",
        "  - Complete the `valid()` function\n",
        "  - Tune the hyperparameters in `train_config`\n",
        "  - Implement 2nd-order polynomial regression model (without interaction terms) in `minibatch_2()`\n",
        "  - Implement feature normalization in `normalize_train_data()`\n",
        "  - Feature selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqMEWsRekx0L"
      },
      "source": [
        "# **Fix random seed**\n",
        "\n",
        "\n",
        "This is for the reproduction of your result. **DO NOT modify this secton!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UxDA6fJb_Uem"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed: 335144792\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "seed = time.time().as_integer_ratio()[0] % (2**32 - 1)\n",
        "seed = 335144792\n",
        "print(\"Random Seed:\", seed)\n",
        "np.random.seed(seed)\n",
        "# feats = [14]\n",
        "# 335144792 loss = 0.18765955809098803\n",
        "# 289140301 loss = 0.22291424418973896\n",
        "# 469040481 loss =  0.1556507066410162\n",
        "# 2483168760 loss =  0.21035390971386417"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OVRMuTAc1_E"
      },
      "source": [
        "# **Download training data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Zo8JUp5kJ4",
        "outputId": "b9204435-62e0-4946-a0cf-a8d094051c25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'gdown' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n",
            "'gdown' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
          ]
        }
      ],
      "source": [
        "!gdown --id \"1Hfzrcm69QwdFvdeF0uASoQlcVxKw_hHy\" --output \"train.csv\"\n",
        "!gdown --id '155N6fzI7vAFzHAGdy6jkaWIksWH6Y1G2' --output \"test.csv\"\n",
        "\n",
        "# Incase the links above die, you can use the following instead.\n",
        "#!gdown --id '11abE854Eyv4BA7qt5k8r_80sJ3KuOQUN' --output \"train.csv\"\n",
        "#!gdown --id '1uod-Z4ztluXnuHtgUbm39nMudUKqXHMl' --output \"test.csv\"\n",
        "\n",
        "# If the data is still missing, you can manually download it from kaggle, and upload the files under /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yHpuZmQwXpz8"
      },
      "outputs": [],
      "source": [
        "def valid(x, y,norm_params):\n",
        "  if y > 20:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "\n",
        "# Create your dataset\n",
        "def parse2train(data, feats,norm_params=None):\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  # Use data #0~#7 to predict #8 => Total data length should be decresased by 8.\n",
        "  total_length = data.shape[1] - 8\n",
        "\n",
        "  for i in range(total_length):\n",
        "    x_tmp = data[feats,i:i+8 ] # Use data #0~#7 to predict #8, data #1~#8 to predict #9, etc.\n",
        "    y_tmp = data[-1, i+8] # last column of (i+8)th row: PM2.5\n",
        "    # Filter out extreme values to train.\n",
        "    if valid(x_tmp, y_tmp,norm_params):\n",
        "      x.append(x_tmp.reshape(-1,))\n",
        "      y.append(y_tmp)\n",
        "\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return x,y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyEpvVVQdZ0c"
      },
      "source": [
        "#**Gradient descent**\n",
        "###**RMSProp**\n",
        "1. $v_t=\\beta \\cdot v_{t-1} + (1-\\beta)(\\nabla w_t)^2$\n",
        "2. $w_{t+1}=w_t - \\frac{\\eta}{\\sqrt{(v_t)}+\\epsilon}\\nabla w_t$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* This is our gradient descent algorithm. RMSProp was implemented in `minibatch()`.\n",
        "* You can implement other algorithm, such as SGD or other gradient descent variants listed below, which may (or may not) improve performance.\n",
        "* However, **modules like sklearn and pytorch are not allowed!!!**\n",
        "* Ref:\n",
        "  - Prof. G. Hinton's lecture: https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\n",
        "  - Prof. Hung-Yi Lee's video: https://youtu.be/HYUXEeh3kwY?si=RtLjSj51WK1pmz87\n",
        "\n",
        "###**Adam (RMSProp + Momemtum)**\n",
        "* Ref:\n",
        "  - Paper: https://arxiv.org/pdf/1412.6980\n",
        "  - Prof. Hung-Yi Lee's video: https://youtu.be/HYUXEeh3kwY?si=RtLjSj51WK1pmz87\n",
        "\n",
        "###**AdamW (Adam with decoupled weight decay)**\n",
        "* Ref:\n",
        "  - Paper: https://arxiv.org/pdf/1711.05101\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KcofxZ8c4kZE"
      },
      "outputs": [],
      "source": [
        "def minibatch(x, y, config):\n",
        "    # Randomize the data in minibatch\n",
        "    index = np.arange(x.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "    x = x[index]\n",
        "    y = y[index]\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "    # Initialization\n",
        "    batch_size = config.batch_size\n",
        "    lr = config.lr\n",
        "    epoch = config.epoch\n",
        "    decay_rate = config.decay_rate\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Linear regression: only contains two parameters (w, b).\n",
        "    # w = np.full(x.shape[1], 0.1).reshape(-1, 1)\n",
        "    w = np.random.uniform(0,1,x[0].shape).reshape(-1, 1)\n",
        "    bias = 0.1\n",
        "\n",
        "    # Optimizer states\n",
        "    cache_w = np.zeros_like(w)\n",
        "    cache_b = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for num in range(epoch):\n",
        "        loss_sum = 0\n",
        "        for b in range(int(x.shape[0] / batch_size)):\n",
        "            x_batch = x[b * batch_size:(b + 1) * batch_size]\n",
        "            y_batch = y[b * batch_size:(b + 1) * batch_size].reshape(-1, 1)\n",
        "\n",
        "            # Prediction of linear regression\n",
        "            pred = np.dot(x_batch, w) + bias\n",
        "\n",
        "            # Loss\n",
        "            loss = y_batch - pred\n",
        "            loss_sum += (loss**2).sum()\n",
        "\n",
        "            # Compute gradient\n",
        "            g_t = np.dot(x_batch.transpose(), loss) * (-2)\n",
        "            g_t_b = loss.sum(axis=0) * (-2)\n",
        "\n",
        "            # Update cache\n",
        "            cache_w = decay_rate * cache_w + (1 - decay_rate) * g_t**2\n",
        "            cache_b = decay_rate * cache_b + (1 - decay_rate) * g_t_b**2\n",
        "\n",
        "            # Update weight & bias\n",
        "            w -= lr * g_t / (np.sqrt(cache_w) + epsilon)\n",
        "            bias -= lr * g_t_b / (np.sqrt(cache_b) + epsilon)\n",
        "        print(\"Epoch %d/%d\" % (num+1, epoch),end=' ')\n",
        "        print(\"loss = \", np.sqrt(loss_sum/x.shape[0]))\n",
        "\n",
        "    return w, bias\n",
        "\n",
        "# TODO: Implement 2-nd polynomial regression version for the report.\n",
        "def minibatch_2(x, y, config):\n",
        "    # Randomize the data in minibatch\n",
        "    index = np.arange(x.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "    x = x[index]\n",
        "    x2 = x ** 2\n",
        "    x = np.concatenate((x, x2), axis=1)\n",
        "    y = y[index]\n",
        "\n",
        "    # Initialization\n",
        "    batch_size = config.batch_size\n",
        "    lr = config.lr\n",
        "    epoch = config.epoch\n",
        "    decay_rate = config.decay_rate\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Linear regression: only contains two parameters (w, b).\n",
        "    # w = np.full(x.shape[1], 0.1).reshape(-1, 1)\n",
        "    w = np.random.uniform(0,1,x[0].shape).reshape(-1, 1)\n",
        "    bias = 0\n",
        "\n",
        "    # Optimizer states\n",
        "    cache_w = np.zeros_like(w)\n",
        "    cache_b = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for num in range(epoch):\n",
        "        loss_sum = 0\n",
        "        for b in range(int(x.shape[0] / batch_size)):\n",
        "            x_batch = x[b * batch_size:(b + 1) * batch_size]\n",
        "            y_batch = y[b * batch_size:(b + 1) * batch_size].reshape(-1, 1)\n",
        "\n",
        "            # Prediction of linear regression\n",
        "            pred = np.dot(x_batch, w) + bias\n",
        "\n",
        "            # Loss\n",
        "            loss = y_batch - pred\n",
        "            loss_sum += (loss**2).sum()\n",
        "\n",
        "            # Compute gradient\n",
        "            g_t = np.dot(x_batch.transpose(), loss) * (-2)\n",
        "            g_t_b = loss.sum(axis=0) * (-2)\n",
        "\n",
        "            # Update cache\n",
        "            cache_w = decay_rate * cache_w + (1 - decay_rate) * g_t**2\n",
        "            cache_b = decay_rate * cache_b + (1 - decay_rate) * g_t_b**2\n",
        "\n",
        "            # Update weight & bias\n",
        "            w -= lr * g_t / (np.sqrt(cache_w) + epsilon)\n",
        "            bias -= lr * g_t_b / (np.sqrt(cache_b) + epsilon)\n",
        "        print(\"Epoch %d/%d\" % (num+1, epoch),end=' ')\n",
        "        print(\"loss = \", np.sqrt(loss_sum/x.shape[0]))\n",
        "\n",
        "    return w, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZpdOsMfXLxH2"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# TODO: Tune the config to boost your performance.\n",
        "train_config = Namespace(\n",
        "    batch_size = 8,\n",
        "    lr = 0.001,\n",
        "    epoch = 30,\n",
        "    decay_rate = 0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay-RhqqA88vS"
      },
      "source": [
        "# **Training your regression model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EoR5Q5kvJm4t",
        "outputId": "5e24e2ff-04ef-4f18-acd7-755d5ba6371f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_df\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RbM6K-e6dTz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature correlations to PM2.5:\n",
            " PM2.5         1.000000\n",
            "PM10          0.818868\n",
            "CO            0.659148\n",
            "NO2           0.554274\n",
            "NOx           0.513650\n",
            "SO2           0.361333\n",
            "O3            0.233924\n",
            "NO            0.227219\n",
            "AMB_TEMP      0.176147\n",
            "WD_HR         0.171932\n",
            "WIND_DIREC    0.137658\n",
            "WS_HR         0.102047\n",
            "WIND_SPEED    0.101197\n",
            "RH            0.081576\n",
            "RAINFALL      0.060801\n",
            "Name: PM2.5, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# TODO: Normalize each column (except PM2.5) for the report (use z-score normalization)\n",
        "def normalize_train_data(df):\n",
        "\n",
        "    mean = df.mean(axis=0)\n",
        "    std = df.std(axis=0)\n",
        "\n",
        "    data_norm = df.copy()\n",
        "    for col in df.columns:\n",
        "        if col != 'PM2.5':\n",
        "            data_norm[col] = (df[col] - mean[col]) / std[col]\n",
        "            \n",
        "    norm_params = {}\n",
        "    mean = mean.to_dict()\n",
        "    std = std.to_dict()\n",
        "    for key in mean.keys():\n",
        "        if key != 'PM2.5':\n",
        "            norm_params[key] = {'mean': mean[key], 'std': std[key]}\n",
        "            \n",
        "    return data_norm, norm_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Akqj5yYVGHA"
      },
      "outputs": [],
      "source": [
        "# Choose your features to train.\n",
        "# Hint:\n",
        "# 1. You can select more than one feature.\n",
        "# 2. You should select \"good\" features.\n",
        "\n",
        "# TODO: Carefully justify which feature should be chosen.\n",
        "# 0:AMB_TEMP,1:CO, 2:NO,3:NO2,4:NOx,5:O3,6:PM10,7:WS_HR,8:RAINFALL,9:RH,10:SO2,11:WD_HR,12:WIND_DIREC,13:WIND_SPEED,14:PM2.5\n",
        "\n",
        "feats = [14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiEWGMQXLM99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal least square loss: 2.831670901092229\n",
            "Feature 0 correlation with PM2.5: 0.5201\n",
            "Feature 1 correlation with PM2.5: 0.5452\n",
            "Feature 2 correlation with PM2.5: 0.5703\n",
            "Feature 3 correlation with PM2.5: 0.5998\n",
            "Feature 4 correlation with PM2.5: 0.6385\n",
            "Feature 5 correlation with PM2.5: 0.6873\n",
            "Feature 6 correlation with PM2.5: 0.7402\n",
            "Feature 7 correlation with PM2.5: 0.8206\n"
          ]
        }
      ],
      "source": [
        "# Training data preprocessing\n",
        "def train_processing(train_df, norm=False):\n",
        "    \"\"\"Process training train_df with optional normalization\"\"\"\n",
        "\n",
        "    if norm:\n",
        "        # Normalize training data and save parameters (mean & std)\n",
        "        data_norm, norm_params = normalize_train_data(train_df)\n",
        "        data_values = data_norm.values\n",
        "    else:\n",
        "        # Use raw training data\n",
        "        data_values = train_df.values\n",
        "        norm_params = None\n",
        "\n",
        "    # Common processing steps\n",
        "    train_data = np.transpose(np.array(np.float64(data_values)))\n",
        "    train_x, train_y = parse2train(train_data, feats,norm_params)\n",
        "\n",
        "    return train_x, train_y, norm_params\n",
        "\n",
        "train_x, train_y, norm_params = train_processing(train_df, norm=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhfoPJUhcnH9",
        "outputId": "d53d4c90-bdbe-4f87-b1a7-f1e27a6398f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5055, 8) (5055,)\n",
            "Epoch 1/30 loss =  19.012615393688378\n",
            "Epoch 2/30 loss =  3.588881279588541\n",
            "Epoch 3/30 loss =  3.1995768218521192\n",
            "Epoch 4/30 loss =  3.076694659942875\n",
            "Epoch 5/30 loss =  3.013505429005811\n",
            "Epoch 6/30 loss =  2.969781626890356\n",
            "Epoch 7/30 loss =  2.9373173284999607\n",
            "Epoch 8/30 loss =  2.912926188493049\n",
            "Epoch 9/30 loss =  2.894592642938259\n",
            "Epoch 10/30 loss =  2.88083378053891\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/30 loss =  2.8705226980731786\n",
            "Epoch 12/30 loss =  2.8628008882436013\n",
            "Epoch 13/30 loss =  2.85701754776689\n",
            "Epoch 14/30 loss =  2.8526822966955865\n",
            "Epoch 15/30 loss =  2.8494275382474687\n",
            "Epoch 16/30 loss =  2.8469787667025415\n",
            "Epoch 17/30 loss =  2.845131507452435\n",
            "Epoch 18/30 loss =  2.8437336634466264\n",
            "Epoch 19/30 loss =  2.84267215328911\n",
            "Epoch 20/30 loss =  2.8418628823135945\n",
            "Epoch 21/30 loss =  2.84124325990675\n",
            "Epoch 22/30 loss =  2.840766639079758\n",
            "Epoch 23/30 loss =  2.8403981950849677\n",
            "Epoch 24/30 loss =  2.8401118751136787\n",
            "Epoch 25/30 loss =  2.839888142112704\n",
            "Epoch 26/30 loss =  2.839712305927198\n",
            "Epoch 27/30 loss =  2.83957328821725\n",
            "Epoch 28/30 loss =  2.8394627075456564\n",
            "Epoch 29/30 loss =  2.8393742007852656\n",
            "Epoch 30/30 loss =  2.8393029190356023\n"
          ]
        }
      ],
      "source": [
        "# Train your regression model\n",
        "w, bias = minibatch(train_x, train_y, train_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019GwPMrbmrB"
      },
      "source": [
        "# **Testing:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FjQNzOb6BeQ"
      },
      "outputs": [],
      "source": [
        "def parse2test(data, feats):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(90):\n",
        "    x_tmp = data[feats,8*i: 8*i+8]\n",
        "    x.append(x_tmp.reshape(-1,))\n",
        "    if i == 89:\n",
        "      # The last one is just a placeholder\n",
        "      y_tmp = 0\n",
        "    else:\n",
        "      y_tmp = data[-1, 8*i+8] # last column of (i+8)th row: PM2.5\n",
        "    y.append(y_tmp)\n",
        "\n",
        "\n",
        "  # x.shape: (n, 15, 8)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs6zgW-_IQFc"
      },
      "outputs": [],
      "source": [
        "def normalize_test_data(df, norm_params):\n",
        "    data_norm = df.copy()\n",
        "\n",
        "    for col, params in norm_params.items():\n",
        "        if col in df.columns:\n",
        "            data_norm[col] = (df[col] - params['mean']) / params['std']\n",
        "\n",
        "    return data_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m00CNh3QHJP5",
        "outputId": "9455fe69-86b5-48b5-f2fb-445421acf0af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AMB_TEMP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NO</th>\n",
              "      <th>NO2</th>\n",
              "      <th>NOx</th>\n",
              "      <th>O3</th>\n",
              "      <th>PM10</th>\n",
              "      <th>WS_HR</th>\n",
              "      <th>RAINFALL</th>\n",
              "      <th>RH</th>\n",
              "      <th>SO2</th>\n",
              "      <th>WD_HR</th>\n",
              "      <th>WIND_DIREC</th>\n",
              "      <th>WIND_SPEED</th>\n",
              "      <th>PM2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.5</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.7</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.8</td>\n",
              "      <td>13.2</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>180.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27.2</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>15.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>192.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.8</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>12.8</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>181.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.7</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>179.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26.4</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4.6</td>\n",
              "      <td>10.1</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>184.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>16.0</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>47.1</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>130.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>15.6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>44.1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>136.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>15.7</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.1</td>\n",
              "      <td>44.1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>133.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>2.7</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>15.1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.6</td>\n",
              "      <td>10.5</td>\n",
              "      <td>11.1</td>\n",
              "      <td>29.9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>24.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>15.8</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>40.5</td>\n",
              "      <td>28.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>133.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     AMB_TEMP    CO   NO   NO2   NOx    O3  PM10  WS_HR  RAINFALL    RH  SO2  \\\n",
              "0        27.5  0.22  0.7   9.0   9.8  13.2  31.0    1.2       0.0  79.0  1.7   \n",
              "1        27.2  0.17  0.4   5.0   5.4  15.7  20.0    1.5       0.0  79.0  1.6   \n",
              "2        26.8  0.17  0.4   4.3   4.8  12.8  16.0    1.6       0.0  81.0  1.3   \n",
              "3        26.7  0.19  0.4   4.1   4.5  12.0  21.0    1.7       0.0  80.0  1.5   \n",
              "4        26.4  0.22  0.4   4.1   4.6  10.1  23.0    2.2       0.0  81.0  1.5   \n",
              "..        ...   ...  ...   ...   ...   ...   ...    ...       ...   ...  ...   \n",
              "715      16.0  0.26  0.3   3.9   4.2  47.1  34.0    2.7       0.0  70.0  0.5   \n",
              "716      15.6  0.25  0.4   3.3   3.7  44.1  27.0    3.0       0.0  74.0  0.6   \n",
              "717      15.7  0.24  0.4   3.7   4.1  44.1  29.0    2.9       0.0  73.0  0.6   \n",
              "718      15.1  0.24  0.6  10.5  11.1  29.9   9.0    0.8       0.0  95.0  0.6   \n",
              "719      15.8  0.28  0.6   6.0   6.7  40.5  28.0    3.0       0.0  74.0  0.5   \n",
              "\n",
              "     WD_HR  WIND_DIREC  WIND_SPEED  PM2.5  \n",
              "0    180.0       171.0         1.2   20.0  \n",
              "1    192.0       187.0         1.9    8.0  \n",
              "2    181.0       180.0         1.8    9.0  \n",
              "3    179.0       188.0         2.3    6.0  \n",
              "4    184.0       186.0         1.9    5.0  \n",
              "..     ...         ...         ...    ...  \n",
              "715  130.0       133.0         2.8   13.0  \n",
              "716  136.0       131.0         3.2   15.0  \n",
              "717  133.0       129.0         2.7   12.0  \n",
              "718   24.0        21.0         1.1    8.0  \n",
              "719  133.0       131.0         2.9   14.0  \n",
              "\n",
              "[720 rows x 15 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.read_csv('/content/test.csv')\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWff4h-MHQwT"
      },
      "outputs": [],
      "source": [
        "# Testing data preprocessing\n",
        "def test_processing(test_df, norm=False, norm_params=norm_params):\n",
        "    if norm:\n",
        "        if norm_params is None:\n",
        "            raise ValueError(\"norm_params required when norm=True\")\n",
        "        # Apply training normalization parameters to testing data\n",
        "        data_norm = normalize_test_data(test_df, norm_params)\n",
        "        data_values = data_norm.values\n",
        "    else:\n",
        "        # Use raw testing data\n",
        "        data_values = test_df.values\n",
        "\n",
        "    # Common processing steps\n",
        "    test_data = np.transpose(np.array(np.float64(data_values)))\n",
        "    test_x, test_y = parse2test(test_data, feats)\n",
        "\n",
        "    return test_x, test_y \n",
        "\n",
        "test_x, test_y = test_processing(test_df, norm=True, norm_params=norm_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWrfEwaEdO6J"
      },
      "source": [
        "# **Write result as .csv**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqEQ1fZ9-WMO",
        "outputId": "05376f79-917f-4b0e-8b0a-f1cf1a8180d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss =  0.1844001431755592\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open('my_sol.csv', 'w', newline='') as csvf:\n",
        "  writer = csv.writer(csvf)\n",
        "  writer.writerow(['Id','Predicted'])\n",
        "\n",
        "  loss_sum = 0.0\n",
        "  for i in range(int(test_x.shape[0])):\n",
        "    if test_x.shape[1] != w.shape[0]:\n",
        "        x2 = test_x[i] ** 2\n",
        "        test_x_i = np.concatenate((test_x[i], x2), axis=0)\n",
        "    else:\n",
        "        test_x_i = test_x[i]\n",
        "    prediction = (np.dot(np.reshape(w,-1),test_x_i) + bias)[0]\n",
        "    writer.writerow([i, prediction])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
