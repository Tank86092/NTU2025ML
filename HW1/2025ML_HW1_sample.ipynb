{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tank86092/2025ML/blob/main/2025ML_HW1_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **2025 ML FALL HW1: PM2.5 Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: MLTAs\n",
        "\n",
        "Methods:\n",
        "* Training with all data\n",
        "* Optimizer: RMSProp (default)\n",
        "* TODOs:\n",
        "  - Complete the `valid()` function\n",
        "  - Tune the hyperparameters in `train_config`\n",
        "  - Implement 2nd-order polynomial regression model (without interaction terms) in `minibatch_2()`\n",
        "  - Implement feature normalization in `normalize_train_data()`\n",
        "  - Feature selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqMEWsRekx0L"
      },
      "source": [
        "# **Fix random seed**\n",
        "\n",
        "\n",
        "This is for the reproduction of your result. **DO NOT modify this secton!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UxDA6fJb_Uem"
      },
      "outputs": [],
      "source": [
        "seed = 9487\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OVRMuTAc1_E"
      },
      "source": [
        "# **Download training data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Zo8JUp5kJ4",
        "outputId": "b9204435-62e0-4946-a0cf-a8d094051c25"
      },
      "outputs": [],
      "source": [
        "# !gdown --id \"1Hfzrcm69QwdFvdeF0uASoQlcVxKw_hHy\" --output \"train.csv\"\n",
        "# !gdown --id '155N6fzI7vAFzHAGdy6jkaWIksWH6Y1G2' --output \"test.csv\"\n",
        "\n",
        "# Incase the links above die, you can use the following instead.\n",
        "#!gdown --id '11abE854Eyv4BA7qt5k8r_80sJ3KuOQUN' --output \"train.csv\"\n",
        "#!gdown --id '1uod-Z4ztluXnuHtgUbm39nMudUKqXHMl' --output \"test.csv\"\n",
        "\n",
        "# If the data is still missing, you can manually download it from kaggle, and upload the files under /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHpuZmQwXpz8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15, 8) 0.0\n",
            "(15, 8) 76.0\n",
            "(15, 8) 1.4\n",
            "(15, 8) 138.0\n",
            "(15, 8) 136.0\n",
            "(15, 8) 1.1\n",
            "(15, 8) 9.0\n",
            "(5774, 15)\n",
            "(7, 120) (7,)\n"
          ]
        }
      ],
      "source": [
        "def valid(x, y):\n",
        "  # TODO: Try to filter out extreme values.\n",
        "  #  ex: If PM2.5 > 100, then we don't use the data to train (return False), otherwise return True,\n",
        "\n",
        "  return True\n",
        "\n",
        "\n",
        "# Create your dataset\n",
        "def parse2train(data, feats):\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  # Use data #0~#7 to predict #8 => Total data length should be decresased by 8.\n",
        "  total_length = data.shape[0] - 8\n",
        "\n",
        "  for i in range(total_length):\n",
        "    x_tmp = data[i:i+8 ,feats] # Use data #0~#7 to predict #8, data #1~#8 to predict #9, etc.\n",
        "    y_tmp = data[i+8, -1] # last column of (i+8)th row: PM2.5\n",
        "    print(x_tmp.shape, y_tmp)\n",
        "    # Filter out extreme values to train.\n",
        "    if valid(x_tmp, y_tmp):\n",
        "      x.append(x_tmp.reshape(-1,))\n",
        "      y.append(y_tmp)\n",
        "\n",
        "  # x.shape: (n, 15, 8)\n",
        "  # y.shape: (n, 1)\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return x,y\n",
        "\n",
        "\n",
        "data = pd.read_csv('train.csv', header=None).iloc[1:, :]\n",
        "data = data.to_numpy()\n",
        "data = data.astype(float)\n",
        "\n",
        "feats = [i for i in range(15)]\n",
        "\n",
        "x,y = parse2train(data, feats)\n",
        "print(data.shape)\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyEpvVVQdZ0c"
      },
      "source": [
        "#**Gradient descent**\n",
        "###**RMSProp**\n",
        "1. $v_t=\\beta \\cdot v_{t-1} + (1-\\beta)(\\nabla w_t)^2$\n",
        "2. $w_{t+1}=w_t - \\frac{\\eta}{\\sqrt{(v_t)}+\\epsilon}\\nabla w_t$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* This is our gradient descent algorithm. RMSProp was implemented in `minibatch()`.\n",
        "* You can implement other algorithm, such as SGD or other gradient descent variants listed below, which may (or may not) improve performance.\n",
        "* However, **modules like sklearn and pytorch are not allowed!!!**\n",
        "* Ref:\n",
        "  - Prof. G. Hinton's lecture: https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf\n",
        "  - Prof. Hung-Yi Lee's video: https://youtu.be/HYUXEeh3kwY?si=RtLjSj51WK1pmz87\n",
        "\n",
        "###**Adam (RMSProp + Momemtum)**\n",
        "* Ref:\n",
        "  - Paper: https://arxiv.org/pdf/1412.6980\n",
        "  - Prof. Hung-Yi Lee's video: https://youtu.be/HYUXEeh3kwY?si=RtLjSj51WK1pmz87\n",
        "\n",
        "###**AdamW (Adam with decoupled weight decay)**\n",
        "* Ref:\n",
        "  - Paper: https://arxiv.org/pdf/1711.05101\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcofxZ8c4kZE"
      },
      "outputs": [],
      "source": [
        "def minibatch(x, y, config):\n",
        "    # Randomize the data in minibatch\n",
        "    index = np.arange(x.shape[0])\n",
        "    np.random.shuffle(index)\n",
        "    x = x[index]\n",
        "    y = y[index]\n",
        "\n",
        "    # Initialization\n",
        "    batch_size = config.batch_size\n",
        "    lr = config.lr\n",
        "    epoch = config.epoch\n",
        "    decay_rate = config.decay_rate\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Linear regression: only contains two parameters (w, b).\n",
        "    w = np.full(x[0].shape, 0.1).reshape(-1, 1)\n",
        "    w\n",
        "    bias = 0.1\n",
        "\n",
        "    # Optimizer states\n",
        "    cache_w = np.zeros_like(w)\n",
        "    cache_b = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for num in range(epoch):\n",
        "        for b in range(int(x.shape[0] / batch_size)):\n",
        "            x_batch = x[b * batch_size:(b + 1) * batch_size]\n",
        "            y_batch = y[b * batch_size:(b + 1) * batch_size].reshape(-1, 1)\n",
        "\n",
        "            # Prediction of linear regression\n",
        "            pred = np.dot(x_batch, w) + bias\n",
        "\n",
        "            # Loss\n",
        "            loss = y_batch - pred\n",
        "\n",
        "            # Compute gradient\n",
        "            g_t = np.dot(x_batch.transpose(), loss) * (-2)\n",
        "            g_t_b = loss.sum(axis=0) * (-2)\n",
        "\n",
        "            # Update cache\n",
        "            cache_w = decay_rate * cache_w + (1 - decay_rate) * g_t**2\n",
        "            cache_b = decay_rate * cache_b + (1 - decay_rate) * g_t_b**2\n",
        "\n",
        "            # Update weight & bias\n",
        "            w -= lr * g_t / (np.sqrt(cache_w) + epsilon)\n",
        "            bias -= lr * g_t_b / (np.sqrt(cache_b) + epsilon)\n",
        "\n",
        "    return w, bias\n",
        "\n",
        "# TODO: Implement 2-nd polynomial regression version for the report.\n",
        "def minibatch_2(x, y, config):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpdOsMfXLxH2"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "# TODO: Tune the config to boost your performance.\n",
        "train_config = Namespace(\n",
        "    batch_size = 3,\n",
        "    lr = 0.1,\n",
        "    epoch = 5,\n",
        "    decay_rate = 0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay-RhqqA88vS"
      },
      "source": [
        "# **Training your regression model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EoR5Q5kvJm4t",
        "outputId": "5e24e2ff-04ef-4f18-acd7-755d5ba6371f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_df\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\lingu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RbM6K-e6dTz"
      },
      "outputs": [],
      "source": [
        "# TODO: Normalize each column (except PM2.5) for the report (use z-score normalization)\n",
        "def normalize_train_data(df):\n",
        "    \"\"\"\n",
        "    Steps:\n",
        "    1. For each column (except PM2.5): calculate mean and std\n",
        "    2. Apply standardization: (column - mean) / std\n",
        "    3. Store normalization parameters for later use on test data\n",
        "\n",
        "    Returns:\n",
        "        normalized_df: DataFrame with normalized features\n",
        "        norm_params: Dict with {'column': {'mean': X, 'std': Y}}\n",
        "\n",
        "    Hint: Loop through data.columns, skip PM2.5\n",
        "    \"\"\"\n",
        "    # Your implementation here\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Akqj5yYVGHA"
      },
      "outputs": [],
      "source": [
        "# Choose your features to train.\n",
        "# Hint:\n",
        "# 1. You can select more than one feature.\n",
        "# 2. You should select \"good\" features.\n",
        "\n",
        "# TODO: Carefully justify which feature should be chosen.\n",
        "feats = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiEWGMQXLM99"
      },
      "outputs": [],
      "source": [
        "# Training data preprocessing\n",
        "def train_processing(train_df, norm=False):\n",
        "    \"\"\"Process training train_df with optional normalization\"\"\"\n",
        "\n",
        "    if norm:\n",
        "        # Normalize training data and save parameters (mean & std)\n",
        "        data_norm, norm_params = normalize_train_data(train_df)\n",
        "        data_values = data_norm.values\n",
        "    else:\n",
        "        # Use raw training data\n",
        "        data_values = train_df.values\n",
        "        norm_params = None\n",
        "\n",
        "    # Common processing steps\n",
        "    train_data = np.transpose(np.array(np.float64(data_values)))\n",
        "    train_x, train_y = parse2train(train_data, feats)\n",
        "\n",
        "    return train_x, train_y, norm_params\n",
        "\n",
        "train_x, train_y, norm_params = train_processing(train_df, norm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhfoPJUhcnH9",
        "outputId": "d53d4c90-bdbe-4f87-b1a7-f1e27a6398f6"
      },
      "outputs": [],
      "source": [
        "# Train your regression model\n",
        "w, bias = minibatch(train_x, train_y, train_config)\n",
        "print(w.shape, bias.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "019GwPMrbmrB"
      },
      "source": [
        "# **Testing:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FjQNzOb6BeQ"
      },
      "outputs": [],
      "source": [
        "def parse2test(data, feats):\n",
        "  x = []\n",
        "  for i in range(90):\n",
        "    x_tmp = data[feats,8*i: 8*i+8]\n",
        "    x.append(x_tmp.reshape(-1,))\n",
        "\n",
        "  # x.shape: (n, 15, 8)\n",
        "  x = np.array(x)\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs6zgW-_IQFc"
      },
      "outputs": [],
      "source": [
        "def normalize_test_data(df, norm_params):\n",
        "    data_norm = df.copy()\n",
        "\n",
        "    for col, params in norm_params.items():\n",
        "        if col in df.columns:\n",
        "            data_norm[col] = (df[col] - params['mean']) / params['std']\n",
        "\n",
        "    return data_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m00CNh3QHJP5",
        "outputId": "9455fe69-86b5-48b5-f2fb-445421acf0af"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('test.csv')\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWff4h-MHQwT"
      },
      "outputs": [],
      "source": [
        "# Testing data preprocessing\n",
        "def test_processing(test_df, norm=False, norm_params=norm_params):\n",
        "    if norm:\n",
        "        if norm_params is None:\n",
        "            raise ValueError(\"norm_params required when norm=True\")\n",
        "\n",
        "        # Apply training normalization parameters to testing data\n",
        "        data_norm = normalize_test_data(test_df, norm_params)\n",
        "        data_values = data_norm.values\n",
        "    else:\n",
        "        # Use raw testing data\n",
        "        data_values = test_df.values\n",
        "\n",
        "    # Common processing steps\n",
        "    test_data = np.transpose(np.array(np.float64(data_values)))\n",
        "    test_x = parse2test(test_data, feats)\n",
        "\n",
        "    return test_x\n",
        "\n",
        "test_x = test_processing(test_df, norm=False, norm_params=norm_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWrfEwaEdO6J"
      },
      "source": [
        "# **Write result as .csv**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqEQ1fZ9-WMO",
        "outputId": "05376f79-917f-4b0e-8b0a-f1cf1a8180d8"
      },
      "outputs": [],
      "source": [
        " with open('my_sol.csv', 'w', newline='') as csvf:\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['Id','Predicted'])\n",
        "\n",
        "    print(test_x.shape)\n",
        "    for i in range(int(test_x.shape[0])):\n",
        "      # Prediction of linear regression\n",
        "      prediction = (np.dot(np.reshape(w,-1),test_x[i]) + bias)[0]\n",
        "      writer.writerow([i, prediction])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
